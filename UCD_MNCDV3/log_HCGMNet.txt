/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
[codecarbon WARNING @ 19:09:11] Multiple instances of codecarbon are allowed to run at the same time.
/bin/dash: 1: scontrol: not found
[codecarbon WARNING @ 19:09:11] Error running `scontrol show job $SLURM_JOB_ID` to count SLURM-available cpus. Using the machine's cpu count.
[codecarbon INFO @ 19:09:11] [setup] RAM Tracking...
/bin/dash: 1: scontrol: not found
[codecarbon WARNING @ 19:09:11] Error running `scontrol show job $SLURM_JOB_ID` to retrieve SLURM-available RAM.Using the machine's total RAM.
[codecarbon INFO @ 19:09:11] [setup] CPU Tracking...
[codecarbon WARNING @ 19:09:12] No CPU tracking mode found. Falling back on estimation based on TDP for CPU. 
 Linux OS detected: Please ensure RAPL files exist, and are readable, at /sys/class/powercap/intel-rapl/subsystem to measure CPU

[codecarbon INFO @ 19:09:12] CPU Model on constant consumption mode: AMD EPYC 7302 16-Core Processor
[codecarbon WARNING @ 19:09:12] No CPU tracking mode found. Falling back on CPU load mode.
/bin/dash: 1: scontrol: not found
[codecarbon WARNING @ 19:09:12] Error running `scontrol show job $SLURM_JOB_ID` to count SLURM-available cpus. Using the machine's cpu count.
[codecarbon INFO @ 19:09:12] [setup] GPU Tracking...
[codecarbon INFO @ 19:09:12] Tracking Nvidia GPU via pynvml
[codecarbon INFO @ 19:09:12] The below tracking methods have been set up:
                RAM Tracking Method: RAM power estimation model
                CPU Tracking Method: cpu_load
                GPU Tracking Method: pynvml
            
[codecarbon INFO @ 19:09:12] >>> Tracker's metadata:
[codecarbon INFO @ 19:09:12]   Platform system: Linux-3.10.0-1160.6.1.el7.x86_64-x86_64-with-glibc2.35
[codecarbon INFO @ 19:09:12]   Python version: 3.10.12
[codecarbon INFO @ 19:09:12]   CodeCarbon version: 3.1.1
[codecarbon INFO @ 19:09:12]   Available RAM : 1007.782 GB
[codecarbon INFO @ 19:09:12]   CPU count: 32 thread(s) in 2 physical CPU(s)
[codecarbon INFO @ 19:09:12]   CPU model: AMD EPYC 7302 16-Core Processor
[codecarbon INFO @ 19:09:12]   GPU count: 4
[codecarbon INFO @ 19:09:12]   GPU model: 4 x NVIDIA A100-SXM4-40GB BUT only tracking these GPU ids : ['0', '1', '2', '3']
[codecarbon INFO @ 19:09:15] Emissions data (if any) will be saved to file /bigdata/3dabc/MNCD/UCD_MNCDV3/emissions.csv
Detected kernel version 3.10.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_BN_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_BN_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
The model HCGMNet contains a sigmoid activation at its end, the 'num_classes' has been set to the default value 1, please make sure using it for binary change detection.
loading HCGMNet
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace=True)
    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU(inplace=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (9): ReLU(inplace=True)
    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (12): ReLU(inplace=True)
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (16): ReLU(inplace=True)
    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (19): ReLU(inplace=True)
    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (26): ReLU(inplace=True)
    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (29): ReLU(inplace=True)
    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (32): ReLU(inplace=True)
    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (36): ReLU(inplace=True)
    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (39): ReLU(inplace=True)
    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (42): ReLU(inplace=True)
    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
model loaded
{'data_type': 'MNCDV3', 'dataset_name': 'MNCDV3', 'dataset_path': '/bigdata/3dabc/MNCD/MNCDV3_Bitemporal_Cropped_Size224_Step112', 'eval': {'batch_size': 16, 'evaluator': 'torchmetrics'}, 'input_nc': 9, 'model_name': 'HCGMNet', 'num_classes': 2, 'push_to_hub': False, 'test': {'batch_size': 16, 'save_path': './results/'}, 'train': {'batch_size': 16, 'epochs': 50, 'loss': 'BCE', 'lr': 0.0001, 'optim': 'Adam', 'save_intervals': 1, 'snapshots_dir': './checkpoints/'}}
Loading weights from local directory
model loaded
testing:
Data Transformation: [ToTensor()]
{'data_type': 'MNCDV3', 'dataset_name': 'MNCDV3', 'dataset_path': '/bigdata/3dabc/MNCD/MNCDV3_Bitemporal_Cropped_Size224_Step112', 'eval': {'batch_size': 16, 'evaluator': 'torchmetrics'}, 'input_nc': 9, 'model_name': 'HCGMNet', 'num_classes': 2, 'push_to_hub': False, 'test': {'batch_size': 16, 'save_path': './results/'}, 'train': {'batch_size': 16, 'epochs': 50, 'loss': 'BCE', 'lr': 0.0001, 'optim': 'Adam', 'save_intervals': 1, 'snapshots_dir': './checkpoints/'}}
Building dataloader from /bigdata/3dabc/MNCD/MNCDV3_Bitemporal_Cropped_Size224_Step112
dataset type is: MNCDV3
Number of testing samples: 699
  0%|          | 0/44 [00:00<?, ?it/s] 45%|████▌     | 20/44 [00:04<00:04,  4.83it/s] 91%|█████████ | 40/44 [00:07<00:00,  5.12it/s]100%|██████████| 44/44 [00:08<00:00,  5.17it/s]
[codecarbon INFO @ 19:09:27] 
Graceful stopping: collecting and writing information.
Please wait a few seconds...
/bin/dash: 1: scontrol: not found
[codecarbon WARNING @ 19:09:27] Error running `scontrol show job $SLURM_JOB_ID` to retrieve SLURM-available RAM.Using the machine's total RAM.
[codecarbon INFO @ 19:09:27] Energy consumed for RAM : 0.000220 kWh. RAM Power : 70.0 W
[codecarbon INFO @ 19:09:27] Delta energy consumed for CPU with cpu_load : 0.000098 kWh, power : 31.068048505818183 W
[codecarbon INFO @ 19:09:27] Energy consumed for All CPU : 0.000098 kWh
[codecarbon INFO @ 19:09:27] Energy consumed for all GPUs : 0.001131 kWh. Total GPU Power : 343.97611654827404 W
[codecarbon INFO @ 19:09:27] 0.001450 kWh of electricity and 0.000000 L of water were used since the beginning.
[codecarbon INFO @ 19:09:27] Done!

465959 33057676 718366 831023
Model_Tested=HCGMNet, Accuracy=0.9558, Precision=0.3934, Recall=0.3593, cF1=0.3756, ciou=0.2312
